{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> &uarr;   Ensure Kernel is set to  &uarr;  </div><br><div style=\"text-align: right\"> \n",
    "conda_amazonei_pytorch_latest_p36  </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U sagemaker\n",
    "#restart your kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastAI Training using SageMaker Bring your own Container (BYOC)\n",
    "\n",
    "In this notebook, we will cover how to bring our own container with either a framework or algorithm to train a model on SageMaker. \n",
    "\n",
    "We will use fastai in this case and build our container with custom training code integrated into the container. The other option is to use script mode which is easily done by changing the entrypoint.\n",
    "\n",
    "The outline of this notebook is \n",
    "\n",
    "1. **Build docker image** for FastAI and serving and training code (provided).\n",
    "\n",
    "2. Log into ECR, tag and **push docker image to ECR**\n",
    "\n",
    "3. Use the FastAI container image in SageMaker to **train model**\n",
    "\n",
    "4. **Deploy model** to endpoint using the container image\n",
    "\n",
    "5. **Test inference** using an image in couple of possible ways "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Container Image\n",
    "Let's start with building a container image locally and then push that to ECR (Elastic Container Registry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/sageMakerWorkshop/byoc/docker\n"
     ]
    }
   ],
   "source": [
    "%cd ~/SageMaker/sageMakerWorkshop/byoc/docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon   12.8kB\n",
      "Step 1/8 : FROM fastdotai/fastai:2021-02-11\n",
      " ---> c15a6ed2e7f0\n",
      "Step 2/8 : LABEL maintainer=\"Raj Kadiyala\"\n",
      " ---> Running in 78929be9a70c\n",
      "Removing intermediate container 78929be9a70c\n",
      " ---> c8519e4295ec\n",
      "Step 3/8 : WORKDIR /\n",
      " ---> Running in ea5d9472f850\n",
      "Removing intermediate container ea5d9472f850\n",
      " ---> 253118e580b5\n",
      "Step 4/8 : RUN pip3 install --no-cache --upgrade requests\n",
      " ---> Running in bee595f2f4a7\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (2.24.0)\n",
      "Collecting requests\n",
      "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests) (2020.12.5)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Installing collected packages: charset-normalizer, requests\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.24.0\n",
      "    Uninstalling requests-2.24.0:\n",
      "      Successfully uninstalled requests-2.24.0\n",
      "Successfully installed charset-normalizer-2.0.12 requests-2.27.1\n",
      "Removing intermediate container bee595f2f4a7\n",
      " ---> 08eb32013bc6\n",
      "Step 5/8 : ENV PYTHONDONTWRITEBYTECODE=1     PYTHONUNBUFFERED=1     LD_LIBRARY_PATH=\"${LD_LIBRARY_PATH}:/usr/local/lib\"     PYTHONIOENCODING=UTF-8     LANG=C.UTF-8     LC_ALL=C.UTF-8\n",
      " ---> Running in 031e1c9c3075\n",
      "Removing intermediate container 031e1c9c3075\n",
      " ---> dc1e8fa1405c\n",
      "Step 6/8 : RUN pip3 install --no-cache --upgrade     sagemaker-training\n",
      " ---> Running in 630135f63c3b\n",
      "Collecting sagemaker-training\n",
      "  Downloading sagemaker_training-4.1.1.tar.gz (47 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sagemaker-training) (1.19.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sagemaker-training) (1.15.0)\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (from sagemaker-training) (20.3.3)\n",
      "Requirement already satisfied: werkzeug>=0.15.5 in /opt/conda/lib/python3.7/site-packages (from sagemaker-training) (1.0.1)\n",
      "Requirement already satisfied: psutil>=5.6.7 in /opt/conda/lib/python3.7/site-packages (from sagemaker-training) (5.7.2)\n",
      "Requirement already satisfied: protobuf>=3.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker-training) (3.14.0)\n",
      "Requirement already satisfied: scipy>=1.2.2 in /opt/conda/lib/python3.7/site-packages (from sagemaker-training) (1.6.0)\n",
      "Collecting inotify_simple==1.2.1\n",
      "  Downloading inotify_simple-1.2.1.tar.gz (7.9 kB)\n",
      "Collecting paramiko>=2.4.2\n",
      "  Downloading paramiko-2.11.0-py2.py3-none-any.whl (212 kB)\n",
      "Requirement already satisfied: cryptography>=2.5 in /opt/conda/lib/python3.7/site-packages (from paramiko>=2.4.2->sagemaker-training) (3.3.1)\n",
      "Collecting bcrypt>=3.1.3\n",
      "  Downloading bcrypt-3.2.2-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (62 kB)\n",
      "Requirement already satisfied: cffi>=1.1 in /opt/conda/lib/python3.7/site-packages (from bcrypt>=3.1.3->paramiko>=2.4.2->sagemaker-training) (1.14.4)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4.2->sagemaker-training) (2.20)\n",
      "Collecting pynacl>=1.0.1\n",
      "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
      "Collecting retrying>=1.3.3\n",
      "  Downloading retrying-1.3.3.tar.gz (10 kB)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.23.7-py3-none-any.whl (132 kB)\n",
      "Collecting botocore<1.27.0,>=1.26.7\n",
      "  Downloading botocore-1.26.7-py3-none-any.whl (8.8 MB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.27.0,>=1.26.7->boto3->sagemaker-training) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.27.0,>=1.26.7->boto3->sagemaker-training) (1.25.11)\n",
      "Collecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
      "Collecting s3transfer<0.6.0,>=0.5.0\n",
      "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
      "Collecting gevent\n",
      "  Downloading gevent-21.12.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (5.8 MB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from gevent->sagemaker-training) (51.1.2.post20210112)\n",
      "Collecting greenlet<2.0,>=1.1.0\n",
      "  Downloading greenlet-1.1.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (150 kB)\n",
      "Collecting zope.event\n",
      "  Downloading zope.event-4.5.0-py2.py3-none-any.whl (6.8 kB)\n",
      "Collecting zope.interface\n",
      "  Downloading zope.interface-5.4.0-cp37-cp37m-manylinux2010_x86_64.whl (251 kB)\n",
      "Building wheels for collected packages: sagemaker-training, inotify-simple, retrying\n",
      "  Building wheel for sagemaker-training (setup.py): started\n",
      "  Building wheel for sagemaker-training (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker-training: filename=sagemaker_training-4.1.1-cp37-cp37m-linux_x86_64.whl size=76294 sha256=a6d2b3db3689e7ab77797dd64f396b791d65d4a99ed1cecad83898231ef03f9c\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-5g33y0kh/wheels/d8/af/09/e1b5f218ea38d27aa82269516a31725c2e9127d5e19b2ff6ac\n",
      "  Building wheel for inotify-simple (setup.py): started\n",
      "  Building wheel for inotify-simple (setup.py): finished with status 'done'\n",
      "  Created wheel for inotify-simple: filename=inotify_simple-1.2.1-py3-none-any.whl size=8203 sha256=ea49d70b4d45082ec0b49457fe5a4745aa60764b8dbf2c8bfedce698946f799e\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-5g33y0kh/wheels/ef/7e/4a/bfeb3216a60ab5e077958f5a1e980cc3de9663155cfb31c660\n",
      "  Building wheel for retrying (setup.py): started\n",
      "  Building wheel for retrying (setup.py): finished with status 'done'\n",
      "  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=11429 sha256=0b33efbf2d2191e8686963af0c920f4aa582ad805de0723a76abc7456b6d6700\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-5g33y0kh/wheels/f9/8d/8d/f6af3f7f9eea3553bc2fe6d53e4b287dad18b06a861ac56ddf\n",
      "Successfully built sagemaker-training inotify-simple retrying\n",
      "Installing collected packages: jmespath, botocore, zope.interface, zope.event, s3transfer, pynacl, greenlet, bcrypt, retrying, paramiko, inotify-simple, gevent, boto3, sagemaker-training\n",
      "Successfully installed bcrypt-3.2.2 boto3-1.23.7 botocore-1.26.7 gevent-21.12.0 greenlet-1.1.2 inotify-simple-1.2.1 jmespath-1.0.0 paramiko-2.11.0 pynacl-1.5.0 retrying-1.3.3 s3transfer-0.5.2 sagemaker-training-4.1.1 zope.event-4.5.0 zope.interface-5.4.0\n",
      "Removing intermediate container 630135f63c3b\n",
      " ---> 47460d829ef1\n",
      "Step 7/8 : COPY code/* /opt/ml/code/\n",
      " ---> f99c8cbcbf72\n",
      "Step 8/8 : ENV SAGEMAKER_PROGRAM train.py\n",
      " ---> Running in fe98ef39f7fc\n",
      "Removing intermediate container fe98ef39f7fc\n",
      " ---> 15bb4e9aaa2a\n",
      "Successfully built 15bb4e9aaa2a\n",
      "Successfully tagged fastai:latest\n"
     ]
    }
   ],
   "source": [
    "!docker build -t fastai ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY         TAG          IMAGE ID       CREATED         SIZE\n",
      "fastai             latest       15bb4e9aaa2a   4 seconds ago   7.53GB\n",
      "fastdotai/fastai   2021-02-11   c15a6ed2e7f0   15 months ago   7.43GB\n"
     ]
    }
   ],
   "source": [
    "!docker images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the ecr details and tags \n",
    "Lets set a few params here like ecr name space , tag name etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "ecr_namespace = \"sagemaker-training-containers/\"\n",
    "prefix = \"script-mode-container-fastai\"\n",
    "\n",
    "ecr_repository_name = ecr_namespace + prefix\n",
    "role = get_execution_role()\n",
    "account_id = role.split(\":\")[4]\n",
    "region = boto3.Session().region_name\n",
    "tag_name=account_id+'.dkr.ecr.'+region+'.amazonaws.com/'+ecr_repository_name+':latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'601877770506.dkr.ecr.us-east-1.amazonaws.com/sagemaker-training-containers/script-mode-container-fastai:latest'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we tag our image with the tag name we generated above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker tag fastai $tag_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ECR Repository and push steps\n",
    "\n",
    "All of these can be scripted out but they are laid out this way for transparency and step evolution understanding\n",
    "\n",
    "First we get a token credential to ECR. This will allow us to perform ECR operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "!$(aws ecr get-login --no-include-email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create an ECR repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "An error occurred (RepositoryAlreadyExistsException) when calling the CreateRepository operation: The repository with name 'sagemaker-training-containers/script-mode-container-fastai' already exists in the registry with id '601877770506'\n"
     ]
    }
   ],
   "source": [
    "!aws ecr create-repository --repository-name $ecr_repository_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our ECR respoitory has been created, we can now push our docker image to it with the tag name we assigned to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [601877770506.dkr.ecr.us-east-1.amazonaws.com/sagemaker-training-containers/script-mode-container-fastai]\n",
      "\n",
      "\u001b[1B8d942104: Preparing \n",
      "\u001b[1Bbb450374: Preparing \n",
      "\u001b[1Bee6e32ab: Preparing \n",
      "\u001b[1B03119f42: Preparing \n",
      "\u001b[1B9d9efed5: Preparing \n",
      "\u001b[1B5dee3f41: Preparing \n",
      "\u001b[1Be46047de: Preparing \n",
      "\u001b[1Bea1e71e9: Preparing \n",
      "\u001b[1Bbf18a086: Preparing \n",
      "\u001b[1Bfc49132e: Preparing \n",
      "\u001b[1B5e116b6d: Preparing \n",
      "\u001b[1B5da50cc0: Preparing \n",
      "\u001b[1B722bdc07: Preparing \n",
      "\u001b[1Bb673a1d6: Preparing \n",
      "\u001b[1B150d2459: Preparing \n",
      "\u001b[1B6268583e: Preparing \n",
      "\u001b[1Bcc6eae8b: Preparing \n",
      "\u001b[1B8881187d: Preparing \n",
      "\u001b[1B5df75b44: Preparing \n",
      "\u001b[19Bb450374: Pushed   97.79MB/95.62MB\u001b[2K\u001b[18A\u001b[2K\u001b[14A\u001b[2K\u001b[20A\u001b[2K\u001b[11A\u001b[2K\u001b[19A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[18A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2Klatest: digest: sha256:46316002efef5f166eeeee183092db2fdd281c45ebffe4f9c63d58878e3cf384 size: 4715\n"
     ]
    }
   ],
   "source": [
    "!docker push $tag_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how we get the URI of our uploaded docker image in ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601877770506.dkr.ecr.us-east-1.amazonaws.com/sagemaker-training-containers/script-mode-container-fastai:latest\n"
     ]
    }
   ],
   "source": [
    "container_image_uri = \"{0}.dkr.ecr.{1}.amazonaws.com/{2}:latest\".format(\n",
    "    account_id, region, ecr_repository_name\n",
    ")\n",
    "print(container_image_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call your custom container to train the model\n",
    "\n",
    "In the cell below, replace **your-unique-bucket-name** with the name of bucket you created in the data-prep notebook<br>\n",
    "**Note:** This cell takes around **20 mins** to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-25 00:21:27 Starting - Starting the training job...\n",
      "2022-05-25 00:21:45 Starting - Preparing the instances for trainingProfilerReport-1653438087: InProgress\n",
      "......\n",
      "2022-05-25 00:22:53 Downloading - Downloading input data......\n",
      "2022-05-25 00:23:39 Training - Downloading the training image..............\u001b[34m2022-05-25 00:26:12,070 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-05-25 00:26:12,102 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-05-25 00:26:12,112 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-05-25 00:26:12,121 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": null,\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"lr\": 0.001\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"script-mode-container-fastai-2022-05-25-00-21-26-874\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"/opt/ml/code\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 48,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.12xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.12xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"lr\":0.001}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.12xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.12xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=48\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=/opt/ml/code\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":null,\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"lr\":0.001},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"script-mode-container-fastai-2022-05-25-00-21-26-874\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":48,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.12xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.12xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--lr\",\"0.001\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.001\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python37.zip:/opt/conda/lib/python3.7:/opt/conda/lib/python3.7/lib-dynload:/opt/conda/lib/python3.7/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python train.py --lr 0.001\u001b[0m\n",
      "\n",
      "2022-05-25 00:26:20 Training - Training image download completed. Training in progress.\u001b[34m/opt/conda/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370156314/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\u001b[0m\n",
      "\u001b[34m['Priority', 'Roundabout', 'Signal']\u001b[0m\n",
      "\u001b[34mDownloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0.00/97.8M [00:00<?, ?B/s]#015  2%|▏         | 1.91M/97.8M [00:00<00:05, 19.7MB/s]#015  4%|▎         | 3.53M/97.8M [00:00<00:05, 18.8MB/s]#015 12%|█▏        | 11.3M/97.8M [00:00<00:03, 24.1MB/s]#015 14%|█▍        | 14.0M/97.8M [00:00<00:03, 23.5MB/s]#015 23%|██▎       | 22.1M/97.8M [00:00<00:02, 30.0MB/s]#015 35%|███▌      | 34.3M/97.8M [00:00<00:01, 39.0MB/s]#015 49%|████▉     | 48.3M/97.8M [00:00<00:01, 50.0MB/s]#015 62%|██████▏   | 60.1M/97.8M [00:00<00:00, 60.7MB/s]#015 72%|███████▏  | 70.2M/97.8M [00:00<00:00, 69.6MB/s]#015 82%|████████▏ | 80.0M/97.8M [00:01<00:00, 75.4MB/s]#015 93%|█████████▎| 90.9M/97.8M [00:01<00:00, 83.9MB/s]#015100%|██████████| 97.8M/97.8M [00:01<00:00, 84.6MB/s]\u001b[0m\n",
      "\u001b[34m█#015epoch     train_loss  valid_loss  error_rate  time    \u001b[0m\n",
      "\u001b[34m█#015█#0150         1.599910    None        None        11:56     \u001b[0m\n",
      "\u001b[34m2022-05-25 00:38:21,191 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-05-25 00:38:45 Uploading - Uploading generated training model\n",
      "2022-05-25 00:38:45 Completed - Training job completed\n",
      "Training seconds: 952\n",
      "Billable seconds: 952\n",
      "CPU times: user 2.21 s, sys: 116 ms, total: 2.33 s\n",
      "Wall time: 17min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sagemaker\n",
    "import json\n",
    "\n",
    "bucket = \"amagroup-workshop-2022\"\n",
    "\n",
    "\n",
    "# JSON encode hyperparameters\n",
    "def json_encode_hyperparameters(hyperparameters):\n",
    "    return {str(k): json.dumps(v) for (k, v) in hyperparameters.items()}\n",
    "\n",
    "\n",
    "hyperparameters = json_encode_hyperparameters({\"lr\":1e-03})\n",
    "\n",
    "est = sagemaker.estimator.Estimator(\n",
    "    container_image_uri,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.12xlarge',\n",
    "    base_job_name=prefix,\n",
    "    hyperparameters=hyperparameters,\n",
    ")\n",
    "\n",
    "train_config = sagemaker.session.TrainingInput(f's3://{bucket}/train')\n",
    "\n",
    "est.fit({\"train\": train_config})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let us print out the trained FastAI model location. You will need this information for the inference step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastAI Model located at \n",
      "s3://sagemaker-us-east-1-601877770506/script-mode-container-fastai-2022-05-25-00-21-26-874/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print(f'FastAI Model located at \\n{est.output_path}{est._current_job_name}/output/model.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attach to a training job that has been left to run \n",
    "\n",
    "If your kernel becomes disconnected and your training has already started, you can reattach to the training job.<br>\n",
    "Simply look up the training job name and replace the **your-training-job-name** and then run the cell below. <br>\n",
    "Once the training job is finished, you can continue the cells after the training cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "training_job_name = 'your-training-job-name'\n",
    "\n",
    "if training_job_name != 'your-training-job-name':\n",
    "    est = sagemaker.estimator.Estimator.attach(training_job_name=training_job_name, sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p36",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
